{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eef0a84a6507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron to Predict TimelineDatasets (t+1, given t, t-1, t-2)\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#show\n",
    "dataset = pandas.read_csv('linux-bp-maxtemp-edited.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "#%%\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "#%%\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(29)\n",
    "#%%\n",
    "\n",
    "# load the dataset\n",
    "dataframe = read_csv('linux-bp-maxtemp.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "#%%\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "print ('%.2f' % train_size)\n",
    "test_size = len(dataset) - train_size\n",
    "print ('%.2f' % test_size)\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "#%%\n",
    "\n",
    "# reshape dataset\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "#%%\n",
    "\n",
    "# create and fit Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=look_back, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)\n",
    "#%%\n",
    "\n",
    "# Estimate model performance\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))\n",
    "#%%\n",
    "\n",
    "# generate predictions for training\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "#%%\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(dataset)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%%\n",
    "print('Next day max temperature: %.2f' % testPredictPlot[len(testPredictPlot)-2])\n",
    "#%%\n",
    "#Uj dataset letrehozasa:\n",
    "newprediction = dataset[len(dataset)-1];\n",
    "newdataset = numpy.append(dataset, newprediction)\n",
    "newdataset = newdataset.astype('float32')\n",
    "print('Next day max temperature: %.2f' % newdataset[len(newdataset)-1])\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def new_create_dataset(newdataset, look_back=3):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(newdataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "\n",
    "for i in range(0,28):\n",
    "    \n",
    "    # define newtest, train_size approx = 1476\n",
    "    newtest= newdataset[(1476):len(newdataset):]\n",
    "    print('%.2f' % len(newtest))\n",
    "  \n",
    "    # reshape dataset\n",
    "\n",
    "    new_testX, new_testY = new_create_dataset(newtest, look_back)\n",
    "    \n",
    "    new_testPredict = model.predict(new_testX)\n",
    "    \n",
    "    # shift test predictions for plotting\n",
    "    new_testPredictPlot = numpy.empty_like(newdataset)\n",
    "    new_testPredictPlot[:, :] = numpy.nan\n",
    "    new_testPredictPlot[len(trainPredict)+(look_back*2)+1:len(newdataset)-1, :] = new_testPredict\n",
    "    \n",
    "   #plt.plot(newdataset)\n",
    "   #plt.plot(new_testPredictPlot)\n",
    "   #plt.show()\n",
    "    \n",
    "    #Make newdataset fresh again\n",
    "    newprediction = newdataset[len(newdataset)-1];\n",
    "    newdataset = numpy.append(newdataset, newprediction)\n",
    "    print('Next day max temperature: %.2f' % newdataset[len(newdataset)-1])\n",
    "    \n",
    "#%%\n",
    "for k in range(1,29):\n",
    "    print('Days max temperature: %.2f\\n' % newdataset[len(newdataset)-k]) #%%NewData\n",
    "\n",
    "#%% nov 8  - nov7 = 01day\n",
    "#%% nov 15 - nov7 = 08days\n",
    "#%% dec 6  - nov7 = 28days\n",
    "print('Next month max temperature: %.2f' % dataset[len(dataset)-1]) #%% dec6\n",
    "print('Next week max temperature: %.2f' % dataset[len(dataset)-8]) #%% nov15\n",
    "print('Next day max temperature: %.2f' % dataset[len(dataset)-28]) #%% nov8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
